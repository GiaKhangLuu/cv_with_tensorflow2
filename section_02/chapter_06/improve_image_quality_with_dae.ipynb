{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1723382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8ad61",
   "metadata": {},
   "source": [
    "In the following experiment, we will try to **up-scale images with the following factor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e9595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6464c19",
   "metadata": {},
   "source": [
    "## **Preparing the Dataset**\n",
    "\n",
    "We will build an input pipeline to train our model to up-sample images of *hands*. As mentioned in the book, it is actually difficult to train models for super-resolution, and they usually only shine when they are **trained and applied to specific categories** of images (i.e., images with some common features that the CNN can learn to exploit). Let us imagine that we are, for instance, building a model to improve low-quality from a company specialized in hand-gesture recognition/capture...\n",
    "\n",
    "\n",
    "### **TensorFlow Datasets - Rock/Paper/Scissors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b28dc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 219.53 MiB (download: 219.53 MiB, generated: Unknown size, total: 219.53 MiB) to /Users/giakhang/tensorflow_datasets/rock_paper_scissors/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db56ea501344e91b55a1891e1c9616a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c4ce4ef2584b639a3016469bf519a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/2520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling rock_paper_scissors-train.tfrecord...:   0%|          | 0/2520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling rock_paper_scissors-test.tfrecord...:   0%|          | 0/372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset rock_paper_scissors downloaded and prepared to /Users/giakhang/tensorflow_datasets/rock_paper_scissors/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "tfds.core.DatasetInfo(\n",
      "    name='rock_paper_scissors',\n",
      "    full_name='rock_paper_scissors/3.0.0',\n",
      "    description=\"\"\"\n",
      "    Images of hands playing rock, paper, scissor game.\n",
      "    \"\"\",\n",
      "    homepage='http://laurencemoroney.com/rock-paper-scissors-dataset',\n",
      "    data_path='/Users/giakhang/tensorflow_datasets/rock_paper_scissors/3.0.0',\n",
      "    download_size=219.53 MiB,\n",
      "    dataset_size=219.23 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(300, 300, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=372, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=2520, num_shards=2>,\n",
      "    },\n",
      "    citation=\"\"\"@ONLINE {rps,\n",
      "    author = \"Laurence Moroney\",\n",
      "    title = \"Rock, Paper, Scissors Dataset\",\n",
      "    month = \"feb\",\n",
      "    year = \"2019\",\n",
      "    url = \"http://laurencemoroney.com/rock-paper-scissors-dataset\"\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "hands_builder = tfds.builder('rock_paper_scissors')\n",
    "hands_builder.download_and_prepare()\n",
    "\n",
    "print(hands_builder.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe96f9",
   "metadata": {},
   "source": [
    "Visualizing some of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4f2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot_image_grid(images, titles=None, figure=None, grayscale=False, transpose=False):\n",
    "    \"\"\"\n",
    "    Plot a grid of n x m images\n",
    "    :param images:       Images in a n x m array\n",
    "    :param titles:       (opt.) List of m titles for each image column\n",
    "    :param figure:       (opt.) Pyplot figure (if None, will be created)\n",
    "    :param grayscale:    (opt.) Flag to draw the images in grayscale\n",
    "    :param transpose:    (opt.) Flag to transpose the grid\n",
    "    :return:             Pyplot figure filled with the images\n",
    "    \"\"\"\n",
    "    num_cols, num_rows = len(images), len(images[0])\n",
    "    img_ratio = images[0][0].shape[1] / images[0][0].shape[0]\n",
    "\n",
    "    if transpose:\n",
    "        vert_grid_shape, hori_grid_shape = (1, num_rows), (num_cols, 1)\n",
    "        figsize = (int(num_rows * 5 * img_ratio), num_cols * 5)\n",
    "        wspace, hspace = 0.2, 0.\n",
    "    else:\n",
    "        vert_grid_shape, hori_grid_shape = (num_rows, 1), (1, num_cols)\n",
    "        figsize = (int(num_cols * 5 * img_ratio), num_rows * 5)\n",
    "        hspace, wspace = 0.2, 0.\n",
    "\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=figsize)\n",
    "    imshow_params = {'cmap': plt.get_cmap('gray')} if grayscale else {}\n",
    "    grid_spec = gridspec.GridSpec(*hori_grid_shape, wspace=0, hspace=0)\n",
    "\n",
    "    for j in range(num_cols):\n",
    "        grid_spec_j = gridspec.GridSpecFromSubplotSpec(\n",
    "            *vert_grid_shape, subplot_spec=grid_spec[j], wspace=wspace, hspace=hspace)\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            ax_img = figure.add_subplot(grid_spec_j[i])\n",
    "            # ax_img.axis('off')\n",
    "            ax_img.set_yticks([])\n",
    "            ax_img.set_xticks([])\n",
    "            if titles is not None:\n",
    "                if transpose:\n",
    "                    ax_img.set_ylabel(titles[j], fontsize=25)\n",
    "                else:\n",
    "                    ax_img.set_title(titles[j], fontsize=15)\n",
    "            ax_img.imshow(images[j][i], **imshow_params)\n",
    "\n",
    "    figure.tight_layout()\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612c445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a40d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c78b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22aa5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62e811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4fd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f6e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cb517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c87a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed338b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66e6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
