{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e73c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Layer, Conv2D, BatchNormalization, GlobalAveragePooling2D,\n",
    "                                     MaxPooling2D, Dense, InputLayer, add, Activation, Flatten)\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import math\n",
    "from functools import partial\n",
    "(Ni)\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75e6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvWithBatchNorm(Conv2D):\n",
    "    \"\"\"Conv layer with batch norm\"\"\"\n",
    "    \n",
    "    def __init__(self, activation='relu', name='convbn', **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the layer.\n",
    "        :param activation: Activation function (name or callable)\n",
    "        :param name: Name suffix for the sub-layers\n",
    "        :param kwargs: Mandatory and optional parameters of Conv2D\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(activation=None, name=name + '_c', **kwargs)\n",
    "        self.activation = Activation(activation, name=name + '_act') \\\n",
    "                            if activation is not None else None\n",
    "        self.batch_norm = BatchNormalization(name=name + '_b')     \n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Call the layer operation.\n",
    "        :param inputs: Input tensor to process\n",
    "        :param training: Flag to let TF knows if it is a training iteration or not \n",
    "                         (this will affect the behavior of batch normalization)\n",
    "        :return: Convolved tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        x = super().call(inputs)\n",
    "        x = self.batch_norm(x, training=training)\n",
    "        x = self.activation(x) if self.activation is not None else x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c245f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualMerge(Layer):\n",
    "    \"\"\"Layer to merge the original tensor and the residual one in residual blocks\"\"\"\n",
    "    \n",
    "    def __init__(self, name, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializer the layer.\n",
    "        :param name: Name suffix for the sub-layer\n",
    "        :param kwargs: Optional parameters of Conv2D\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "        self.shortcut = None\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        x_shape = input_shape[0]\n",
    "        x_residual_shape = input_shape[1]\n",
    "        if (x_shape[1] == x_residual_shape[1] and\n",
    "            x_shape[2] == x_residual_shape[2] and\n",
    "            x_shape[3] == x_residual_shape[3]):\n",
    "            self.shortcut = partial(tf.identity, name=self.name + '_shortcut')\n",
    "        else:\n",
    "            strides = (int(round(x_shape[2] / x_residual_shape[2])),  # horizontal strides\n",
    "                      int(round(x_shape[1] / x_residual_shape[1])))  # vertical strides\n",
    "            num_channels = x_residual_shape[3]\n",
    "            self.shortcut = ConvWithBatchNorm(filters=num_channels, kernel_size=(1, 1), \n",
    "                                              strides=strides, activation=None, **self.kwargs,\n",
    "                                              name=self.name + '_shortcut_c')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Call the layer.\n",
    "        :param inputs: Tuples of two tensors to merge\n",
    "        :return x_merge: Merged tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        x, x_residual = inputs\n",
    "        x_shortcut = self.shortcut(x)\n",
    "        x_merge = add([x_shortcut, x_residual])\n",
    "        \n",
    "        return x_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4be1bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicResidualBlock(Model):\n",
    "    \"\"\"Basic residual block\"\"\"\n",
    "    \n",
    "    def __init__(self, filters=64, kernel_size=(3, 3), strides=1, activation='relu', \n",
    "                 kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-4), \n",
    "                 name='res_basic', **kwargs):\n",
    "        \"\"\"Initialize the block\n",
    "        :param filters: Number of filters\n",
    "        :param kernel_size: Kernel size\n",
    "        :param strides: Convolution strides\n",
    "        :param activation: Activation function (name or callable)\n",
    "        :param kernel_initializer: Kernel initialization method name\n",
    "        :param kernel_regularizer: Kernel regularizer\n",
    "        :param name: Name suffix for the sub-layers\n",
    "        :param kwargs: Optional parameters of Conv2D\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "        self.conv1 = ConvWithBatchNorm(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                                      padding='same', activation=activation, name=name + '_cb_1',\n",
    "                                      kernel_initializer=kernel_initializer, \n",
    "                                      kernel_regularizer=kernel_regularizer, **kwargs)\n",
    "        \n",
    "        self.conv2 = ConvWithBatchNorm(filters=filters, kernel_size=kernel_size, strides=1,\n",
    "                                      padding='same', activation=None, name=name + '_cb_2',\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                                      kernel_regularizer=kernel_regularizer, **kwargs)\n",
    "        \n",
    "        self.merge = ResidualMerge(name=name + '_merge', kernel_initializer=kernel_initializer,\n",
    "                                  kernel_regularizer=kernel_regularizer)\n",
    "        \n",
    "        self.activation = Activation(activation, name=name + '_act')\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"Call the layer\n",
    "        :param inputs: Input tensor to process\n",
    "        :param training: Flag to let TF knows if it is a training iteration or not\n",
    "                         (this will affect the behavior of Batch Normalization)\n",
    "        :return x_merge: Block output tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        # Residual path\n",
    "        x_residual = self.conv1(x, training)\n",
    "        x_residual = self.conv2(x_residual, training)\n",
    "        \n",
    "        # Merge residual result with original tensor\n",
    "        x_merge = self.merge([x, x_residual])\n",
    "        x_merge = self.activation(x_merge)\n",
    "        \n",
    "        return x_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067685bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockWithBottleNeck(Model):\n",
    "    \"\"\"Residual block with bottleneck, recommended for deep ResNets (depth > 34)\"\"\"\n",
    "    \n",
    "    def __init__(self, filters=64, kernel_size=(3, 3), strides=1, activation='relu', \n",
    "                kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-4),\n",
    "                name='res_bottleneck', **kwargs):\n",
    "        \"\"\"Initializer the block\n",
    "        :param filters: Number of filters\n",
    "        :param kernel_size: Kernel size\n",
    "        :param strides: Convolution strides\n",
    "        :param activation: Activation function (name or callable)\n",
    "        :param kernel_initializer: Kernel initialization method name\n",
    "        :param kernel_regularizer: Kernel regularizer\n",
    "        :param name: Name suffix for the sub-layers\n",
    "        :param kwargs: Optional parameters of Conv2D\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.conv1 = ConvWithBatchNorm(filters=filters, kernel_size=(1, 1), strides=strides, \n",
    "                                      padding='valid', activation=activation, name=name + '_cb_1',\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                                      kernel_regularizer=kernel_regularizer, **kwargs)\n",
    "        \n",
    "        self.conv2 = ConvWithBatchNorm(filters=filters, kernel_size=kernel_size, strides=1,\n",
    "                                      padding='same', activation=activation, name=name + '_cb_2',\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                                      kernel_regularizer=kernel_regularizer, **kwargs)\n",
    "        \n",
    "        self.conv3 = ConvWithBatchNorm(filters=filters * 4, kernel_size=(1, 1), strides=1,\n",
    "                                      padding='valid', activation=None, name=name + '_cb_3',\n",
    "                                      kernel_initializer=kernel_initializer,\n",
    "                                      kernel_regularizer=kernel_regularizer, **kwargs)\n",
    "        \n",
    "        self.merge = ResidualMerge(name=name + '_merge', kernel_initializer=kernel_initializer,\n",
    "                                  kernel_regularizer=kernel_regularizer)\n",
    "        \n",
    "        self.activation = Activation(activation, name=name + '_act')\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"Call the layer\n",
    "        :param inputs: Input tensor to process\n",
    "        :param training: Flag to let TF knows if it is a training iteration or not\n",
    "                         (this will affect the behavior of Batch Normalization)\n",
    "        :return x_merge: Block ouput tensor\"\"\"\n",
    "        \n",
    "        x = inputs\n",
    "        \n",
    "        # Residual path\n",
    "        x_residual = self.conv1(x, training)\n",
    "        x_residual = self.conv2(x_residual, training)\n",
    "        x_residual = self.conv3(x_residual, training)\n",
    "\n",
    "        # Merge residual result with original tensor\n",
    "        x_merge = self.merge([x, x_residual])\n",
    "        x_merge = self.activation(x_merge)\n",
    "        \n",
    "        return x_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f953edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacroBlock(Sequential):\n",
    "    \"\"\"Macro-block, chaining multiple residual blocks (as a sequential model)\"\"\"\n",
    "    \n",
    "    def __init__(self, block_class=BasicResidualBlock, repetitions=2, filters=64, \n",
    "                kernel_size=(3, 3), strides=1, activation='relu', name='res_macroblock',\n",
    "                kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-4),\n",
    "                **kwargs):\n",
    "        \"\"\"Initialize the block\n",
    "        :param block_class: Block class to be used\n",
    "        :param repetitions: Number of times the block should be repeated inside\n",
    "        :param filters: Number of filters\n",
    "        :param kernel_size: Kernel size\n",
    "        :param strides: Convolution strides\n",
    "        :param activation: Activation function (name or callable)\n",
    "        :param kernel_initializer: Kernel initialization method name\n",
    "        :param kernel_regularizer: Kernel regularizer\n",
    "        :param name: Name suffix for the sub-layers\n",
    "        :param kwargs: Optional parameters of Conv2D\"\"\"\n",
    "        \n",
    "        model =[block_class(filters=filters, kernel_size=kernel_size, \n",
    "                            strides=strides if i == 0 else 1,\n",
    "                            activation=activation, name='{}_{}'.format(name, i + 1),\n",
    "                            kernel_initializer=kernel_initializer,\n",
    "                            kernel_regularizer=kernel_regularizer, **kwargs) \n",
    "                for i in range(repetitions)]\n",
    "        \n",
    "        super().__init__(model, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a3a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(Sequential):\n",
    "    \"\"\"ResNet model for classification\"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, block_class=BasicResidualBlock,\n",
    "                 repetitions=(2, 2, 2, 2), kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=regularizers.l2(1e-4), name='resnet'):\n",
    "        \"\"\"Initialize a ResNet model for classification\n",
    "        :param input_shape: Input shape\n",
    "        :param num_classes: Number of classes to predict\n",
    "        :param block_class: Block class to be used\n",
    "        :param repetitions: List of repetitions for each macro_blocks the network \n",
    "                            should contain\n",
    "        :param kernel_initializer: Kernel initialization method name\n",
    "        :param kernel_regularizer: Kernel regularizer\n",
    "        :param name: Model's name\"\"\"\n",
    "        \n",
    "        filters, strides = 64, 2\n",
    "        \n",
    "        # Initial conv + max_pool layer\n",
    "        conv_1 = [InputLayer(input_shape=input_shape),\n",
    "                  ConvWithBatchNorm(filters=64, kernel_size=(7, 7), strides=strides, \n",
    "                                    padding='same', kernel_initializer=kernel_initializer,\n",
    "                                    kernel_regularizer=kernel_regularizer, activation='relu',\n",
    "                                    name='conv'),\n",
    "                  MaxPooling2D(pool_size=3, strides=strides, padding='same', name='max_pool')]\n",
    "        \n",
    "        # Residual blocks\n",
    "        res_blocks = [MacroBlock(block_class=block_class, repetitions=repet, \n",
    "                                 filters=min(filters * (2 ** i), 1024), kernel_size=(3, 3), \n",
    "                                 strides=1 if i == 0 else strides, activation='relu', \n",
    "                                 kernel_initializer=kernel_initializer, \n",
    "                                 kernel_regularizer=kernel_regularizer, name='block_{}'.format(i + 1)) \n",
    "                      for i, repet in enumerate(repetitions)]\n",
    "        \n",
    "        # Predict layer\n",
    "        predict_layer = [GlobalAveragePooling2D(name='avg_pool'),\n",
    "                        Dense(units=num_classes, activation='softmax', \n",
    "                             kernel_initializer=kernel_initializer, name=name + '_softmax')]\n",
    "        \n",
    "        super().__init__(conv_1 + res_blocks + predict_layer, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7528ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard ResNet versions\n",
    "class ResNet18(ResNet):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, name='resnet18',\n",
    "                 kernel_initializer='he_normal', \n",
    "                 kernel_regularizer=regularizers.l2(1e-4)):\n",
    "        super().__init__(input_shape=input_shape, num_classes=num_classes,\n",
    "                        block_class=BasicResidualBlock, repetitions=(2, 2, 2, 2),\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer, name=name)\n",
    "        \n",
    "class ResNet34(ResNet):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, name='resnet34',\n",
    "                kernel_initializer='he_normal', \n",
    "                kernel_regularizer=regularizers.l2(1e-4)):\n",
    "        super().__init__(input_shape=input_shape, num_classes=num_classes,\n",
    "                        block_class=BasicResidualBlock, repetitions=(3, 4, 6, 3),\n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer, name=name)\n",
    "        \n",
    "class ResNet50(ResNet):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, name='resnet50',\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=regularizers.l2(1e-4)):\n",
    "        super().__init__(input_shape=input_shape, num_classes=num_classes,\n",
    "                        block_class=ResidualBlockWithBottleNeck, \n",
    "                        repetitions=(3, 4, 6, 3), \n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer, name=name)\n",
    "        \n",
    "class ResNet101(ResNet):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, name='resnet101',\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=regularizers.l2(1e-4)):\n",
    "        super().__init__(input_shape=input_shape, num_classes=num_classes,\n",
    "                        block_class=ResidualBlockWithBottleNeck, \n",
    "                        repetitions=(3, 4, 23, 3), \n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer, name=name)\n",
    "        \n",
    "class ResNet152(ResNet):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes=1000, name='resnet152',\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=regularizers.l2(1e-4)):\n",
    "        super().__init__(input_shape=input_shape, num_classes=num_classes,\n",
    "                        block_class=ResidualBlockWithBottleNeck, \n",
    "                        repetitions=(3, 8, 36, 3), \n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8890c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet34\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "conv_c (ConvWithBatchNorm)                   (None, 112, 112, 64)                    9728           \n",
      "____________________________________________________________________________________________________\n",
      "max_pool (MaxPooling2D)                      (None, 56, 56, 64)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "block_1 (MacroBlock)                         (None, 56, 56, 64)                      223104         \n",
      "____________________________________________________________________________________________________\n",
      "block_2 (MacroBlock)                         (None, 28, 28, 128)                     1119872        \n",
      "____________________________________________________________________________________________________\n",
      "block_3 (MacroBlock)                         (None, 14, 14, 256)                     6832384        \n",
      "____________________________________________________________________________________________________\n",
      "block_4 (MacroBlock)                         (None, 7, 7, 512)                       13125120       \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D)            (None, 512)                             0              \n",
      "____________________________________________________________________________________________________\n",
      "resnet34_softmax (Dense)                     (None, 100)                             51300          \n",
      "====================================================================================================\n",
      "Total params: 21,361,508\n",
      "Trainable params: 21,344,484\n",
      "Non-trainable params: 17,024\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50 = ResNet34(num_classes=100, input_shape=input_shape)\n",
    "resnet50.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1d0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
