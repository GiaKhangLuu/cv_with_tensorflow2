{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "build_and_train_cnn",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g64r0dWF9nzM"
      },
      "source": [
        "# Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S1IdOp79PxS",
        "outputId": "7cd5c3fa-8995-468b-d716-8c872f4e1d8c"
      },
      "source": [
        "# Common libs\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "print('Import succesfully')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import succesfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a22f7wL-ixb"
      },
      "source": [
        "# Prepare dataset\n",
        "\n",
        "Download mnist dataset. The dataset contains 60,000 images for the training and 10,000 images for the testing. Then normalize the images from range [0, 255] to [0, 1] and resize to 28 x 28 x 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1cTJxG693U6"
      },
      "source": [
        "num_classes = 10\n",
        "img_rows, img_cols, img_channels = 28, 28, 1\n",
        "input_shape = (img_rows, img_cols, img_channels)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJrNr-uP_g5r"
      },
      "source": [
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
        "X_test = X_test.reshape(X_test.shape[0], *input_shape)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSEakYSmAWmq"
      },
      "source": [
        "# Build and train LeNet5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAWF0A4a_jE6"
      },
      "source": [
        "class LeNet5(Model):\n",
        "\n",
        "  def __init__(self, num_classes):\n",
        "    \"\"\"Create the model and its layer.\n",
        "    :param num_classes: Number of classes to predict from.\n",
        "    \"\"\"\n",
        "\n",
        "    super(LeNet5, self).__init__()\n",
        "    self.conv1 = Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu')\n",
        "    self.conv2 = Conv2D(16, (5, 5), activation='relu')\n",
        "    self.max_pool = MaxPooling2D(pool_size=(2, 2))\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1 = Dense(120, activation='relu')\n",
        "    self.dense2 = Dense(84, activation='relu')\n",
        "    self.dense3 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\" Apply the layers in order to process the input.\n",
        "    :param x: Input tensor\n",
        "    :return: Output tesor\n",
        "    \"\"\"\n",
        "\n",
        "    x = self.max_pool(self.conv1(inputs))  # 1st block\n",
        "    x = self.max_pool(self.conv2(x))  # 2nd block\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense3(self.dense2(self.dense1(x)))  # dense layers\n",
        "    return x"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ofFczQ9Em3e"
      },
      "source": [
        "# Classifying MNIST\n",
        "\n",
        "`sparse_categorical_crossentropy` performs the same as `categorical_crossentropy`, but the former directly takes the ground-truth labels as inputs instead of one one-hot encoded label. Used `sparse_categorical_crossentropy` saves us from manually having to transform the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibsjul8h_rhi"
      },
      "source": [
        "model = LeNet5(num_classes)\n",
        "\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(patience=3, monitor='val_loss'),\n",
        "             TensorBoard(log_dir='./logs', histogram_freq=1)]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TdYdtP9l-Kt"
      },
      "source": [
        "batched_input_shape = tf.TensorShape((None, *input_shape))\n",
        "model.build(input_shape=batched_input_shape)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JIwRy8wmvdD",
        "outputId": "483ef5c2-b297-49c2-b386-4b2905169692"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, \n",
        "          epochs=80, validation_data=(X_test, y_test),\n",
        "          verbose=2, callbacks=callbacks)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "1875/1875 - 5s - loss: 0.5336 - accuracy: 0.8319 - val_loss: 0.1463 - val_accuracy: 0.9563\n",
            "Epoch 2/80\n",
            "1875/1875 - 4s - loss: 0.1314 - accuracy: 0.9599 - val_loss: 0.0826 - val_accuracy: 0.9741\n",
            "Epoch 3/80\n",
            "1875/1875 - 4s - loss: 0.0903 - accuracy: 0.9725 - val_loss: 0.0710 - val_accuracy: 0.9755\n",
            "Epoch 4/80\n",
            "1875/1875 - 4s - loss: 0.0732 - accuracy: 0.9770 - val_loss: 0.0596 - val_accuracy: 0.9798\n",
            "Epoch 5/80\n",
            "1875/1875 - 4s - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.0536 - val_accuracy: 0.9811\n",
            "Epoch 6/80\n",
            "1875/1875 - 4s - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0540 - val_accuracy: 0.9814\n",
            "Epoch 7/80\n",
            "1875/1875 - 4s - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.0439 - val_accuracy: 0.9863\n",
            "Epoch 8/80\n",
            "1875/1875 - 4s - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.0467 - val_accuracy: 0.9841\n",
            "Epoch 9/80\n",
            "1875/1875 - 4s - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.0378 - val_accuracy: 0.9873\n",
            "Epoch 10/80\n",
            "1875/1875 - 4s - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.0397 - val_accuracy: 0.9873\n",
            "Epoch 11/80\n",
            "1875/1875 - 4s - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.0461 - val_accuracy: 0.9853\n",
            "Epoch 12/80\n",
            "1875/1875 - 4s - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.0370 - val_accuracy: 0.9871\n",
            "Epoch 13/80\n",
            "1875/1875 - 4s - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0463 - val_accuracy: 0.9845\n",
            "Epoch 14/80\n",
            "1875/1875 - 4s - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0347 - val_accuracy: 0.9885\n",
            "Epoch 15/80\n",
            "1875/1875 - 4s - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.0460 - val_accuracy: 0.9844\n",
            "Epoch 16/80\n",
            "1875/1875 - 4s - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0453 - val_accuracy: 0.9860\n",
            "Epoch 17/80\n",
            "1875/1875 - 4s - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0421 - val_accuracy: 0.9862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc4c1ffc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIe1H5DpKDs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}